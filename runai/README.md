# Deploy inference workload 

In this task we need to Deploy inference workload using the following image: gcr.io/run-ai-demo/quickstart, create an Helm chart to run the Deployment.

## INSTALLATION WORKFLOW 

** All the outputs in output.txt **

1. Creating a Helm Chart.

2. Editing Chart.yaml file.

3. Creating a namespace for RUN:AI.

4. Creating a RUN:AI Deployment file

5. Creating a Service.

6. Creating a Route.

7. Creating a Values.yaml ​​file.

8. Installation and testing of the Deployment.


### DOCS

https://docs.run.ai/v2.13/developer/cluster-api/other-resources/

https://www.google.com/search?q=how+to+work+with+runai+scheduler+in+kubernetes&sca_esv=569840358&tbm=vid&sxsrf=AM9HkKmVjg0HvgvAypDOech2v1FXERbUJg:1696159955084&source=lnms&sa=X&ved=2ahUKEwjRkOuc4NSBAxVjfKQEHfsEAbcQ_AUoAXoECAIQAw&biw=1440&bih=728&dpr=2#fpstate=ive&vld=cid:f3435d25,vid:PeENP0XO0FQ,st:0

https://helm.sh/docs/helm/helm_create/